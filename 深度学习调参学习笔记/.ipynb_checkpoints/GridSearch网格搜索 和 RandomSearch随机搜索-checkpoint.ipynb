{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文学习于 [调参必备--Grid Search网格搜索](https://www.jianshu.com/p/55b9f2ea283b),[贝叶斯优化(Bayesian Optimization)深入理解](https://www.cnblogs.com/marsggbo/p/9866764.html)和 [scikit-learn User guide](http://sklearn.apachecn.org/#/docs/35),编辑:Weiyang,Time:2019.2.13,weixin:damo894127201 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们都知道机器学习模型是由许多超参数决定的，比如网络深度、学习率、卷积核大小等等，因此为了找到一个最好的超参数组合，最直观的想法就是**穷举搜索(即网格搜索)**。但是我们都知道机器学习训练模型是一个非常耗时的过程，如果想将每种可能的超参数组合都实验一遍，明显不现实，所以网格搜索一般事先限定若干种可能的参数组合，但是这样搜索仍然不高效。因此为了提高搜索效率，便提出了**随机搜索**。虽然随机搜索得到的结果互相之间差异较大，但实验证明**随机搜索的确比网格搜索效果更好**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch:网格搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**网格搜索**又称为**穷举搜索**，在所有候选的每个参数列表中，通过循环遍历，尝试每一种可能性，表现最好的参数就是最终的结果。例如，有两个参数，参数α有三种可能，参数β有4种可能，把所有可能性都列出来后，可以表示为一个4\\*3的表格，其中每格就是一个网格，循环过程就像是在每个网格里遍历搜索，故称为网格搜索。\n",
    "\n",
    "|参数|$\\alpha$=0.1|$\\alpha$=0.01|$\\alpha$=0.001|\n",
    "|:--:|:---------:|:------------:|:------------:|\n",
    "|$\\beta$=0.1|model($\\alpha$=0.1,$\\beta$=0.1)|model($\\alpha$=0.01,$\\beta$=0.1)|model($\\alpha$=0.001,$\\beta$=0.1)|\n",
    "|$\\beta$=0.2|model($\\alpha$=0.1,$\\beta$=0.2)|model($\\alpha$=0.01,$\\beta$=0.2)|model($\\alpha$=0.001,$\\beta$=0.2)|\n",
    "|$\\beta$=0.3|model($\\alpha$=0.1,$\\beta$=0.3)|model($\\alpha$=0.01,$\\beta$=0.3)|model($\\alpha$=0.001,$\\beta$=0.3)|\n",
    "|$\\beta$=0.4|model($\\alpha$=0.1,$\\beta$=0.4)|model($\\alpha$=0.01,$\\beta$=0.4)|model($\\alpha$=0.001,$\\beta$=0.4)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单实现:以两个参数调优为例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造分类伪数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 构造数据集\n",
    "X,Y = make_classification(n_samples=1000,\n",
    "                          n_features=5,\n",
    "                          n_informative=3,\n",
    "                          n_redundant=1,\n",
    "                          n_repeated=1,\n",
    "                          n_classes=2,\n",
    "                         )\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置待调优的两个参数选择范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gammas = [0.001,0.01,0.1,1]\n",
    "Cs = [0.002,0.03,0.4,1.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置评估模型性能的指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里用SVC.score()函数，返回的是测试数据的平均准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_score = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:0.94\n",
      "Best parameters:{'gamma': 1, 'C': 1.2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "raw_model = None\n",
    "for gamma in gammas:\n",
    "    for C in Cs:\n",
    "        model = SVC(gamma=gamma,C=C) # 对于每种参数组合进行一次训练\n",
    "        if raw_model == model: # 判断训练过程中，当前新生成的模型是否是前一训练轮次的模型\n",
    "            print('前后两次训练使用的是同一模型')\n",
    "        model.fit(X_train,Y_train)\n",
    "        score = model.score(X_test,Y_test) # 模型的评估指标\n",
    "        if score > best_score: # 寻找表现最好的参数\n",
    "            best_score = score\n",
    "            best_parameters = {'gamma':gamma,'C':C}\n",
    "        raw_model = model\n",
    "        \n",
    "print('Best score:{:.2f}'.format(best_score))\n",
    "print('Best parameters:{}'.format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然对于每种参数组合，我们都使用了纯净的模型来训练，表面上测试集和参数组合是独立的，但是事实上并非如此，每次训练时，训练集和测试集都是固定的，这就使得结果特别依赖于最初分裂的训练集和测试集，因此为得到更有说服力的**参数组合**，我们需要将**交叉验证**引入进来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网格搜索+交叉验证：GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手动实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构造伪数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 构造数据集\n",
    "X,Y = make_classification(n_samples=1000,\n",
    "                          n_features=5,\n",
    "                          n_informative=3,\n",
    "                          n_redundant=1,\n",
    "                          n_repeated=1,\n",
    "                          n_classes=2,\n",
    "                         )\n",
    "# 将原数据集转为numpy.array\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设置待调优的两个参数选择范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gammas = [0.001,0.01,0.1,1]\n",
    "Cs = [0.002,0.03,0.4,1.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设置评估模型性能的指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 这里用SVC.score()函数，返回的是测试数据的平均准确率\n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 网格搜索 + 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:iter,Best score:0.94,Best parameters:{'gamma': 0.1, 'C': 1.2}\n",
      "2:iter,Best score:0.97,Best parameters:{'gamma': 0.1, 'C': 1.2}\n",
      "3:iter,Best score:0.97,Best parameters:{'gamma': 0.1, 'C': 1.2}\n",
      "4:iter,Best score:0.97,Best parameters:{'gamma': 0.1, 'C': 1.2}\n",
      "5:iter,Best score:0.97,Best parameters:{'gamma': 0.1, 'C': 1.2}\n",
      "6:iter,Best score:0.97,Best parameters:{'gamma': 0.1, 'C': 1.2}\n",
      "7:iter,Best score:0.97,Best parameters:{'gamma': 0.1, 'C': 1.2}\n",
      "8:iter,Best score:0.97,Best parameters:{'gamma': 0.1, 'C': 1.2}\n",
      "9:iter,Best score:0.99,Best parameters:{'gamma': 1, 'C': 1.2}\n",
      "10:iter,Best score:0.99,Best parameters:{'gamma': 1, 'C': 1.2}\n",
      "\n",
      "Best score:0.99\n",
      "Best parameters:{'gamma': 1, 'C': 1.2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "raw_model = None\n",
    "# 交叉验证:10折交叉验证\n",
    "kf = KFold(n_splits=10)\n",
    "iters = 1\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train,Y_train,X_test,Y_test = X[train_index],Y[train_index],X[test_index],Y[test_index]\n",
    "    # 网格搜索\n",
    "    for gamma in gammas:\n",
    "        for C in Cs:\n",
    "            model = SVC(gamma=gamma,C=C) # 对于每种参数组合进行一次训练\n",
    "            if raw_model == model: # 判断训练过程中，当前新生成的模型是否是前一训练轮次的模型\n",
    "                print('前后两次训练使用的是同一模型')\n",
    "            model.fit(X_train,Y_train)\n",
    "            score = model.score(X_test,Y_test) # 模型的评估指标\n",
    "            if score > best_score: # 寻找表现最好的参数\n",
    "                best_score = score\n",
    "                best_parameters = {'gamma':gamma,'C':C}\n",
    "            raw_model = model\n",
    "    print('{}:iter,Best score:{:.2f},Best parameters:{}'.format(iters,best_score,best_parameters))\n",
    "    iters += 1\n",
    "    \n",
    "print()  \n",
    "print('Best score:{:.2f}'.format(best_score))\n",
    "print('Best parameters:{}'.format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn实现: sklearn.model_selection.GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV 参数和类方法介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV() 将**网格搜索**和**交叉验证**结合起来，实现了fit()，predict(),score()等方法，重要的参数如下:\n",
    "1. estimator:实现了scikit-learn的estimator接口，scikit-learn提供的模型都可以\n",
    "2. param_grid:待优化的参数\n",
    "3. cv:默认为None，代表3折交叉验证，可以取int，代表K折交叉验证\n",
    "\n",
    "grid_search = GridSearchCV()\n",
    "GridSearchCV()类实现的方法:\n",
    "1. grid_search.fit(X,Y):用来训练模型和寻找最优参数组合，grid_search是那个最优参数组合的模型\n",
    "2. grid_search.predict(X):在grid_search.fit(X,Y)之后使用，用最优参数组合的那个模型来预测，返回类别\n",
    "3. grid_search.predict_log_proba(X):在grid_search.fit(X,Y)之后使用，用最优参数组合的那个模型来预测，返回取对数后的概率值\n",
    "4. grid_search.predict_proba(X):在grid_search.fit(X,Y)之后使用，用最优参数组合的那个模型来预测，返回概率值\n",
    "5. grid_search.score(X,Y):在grid_search.fit(X,Y)之后使用，用最优参数组合的那个模型来评估测试集，返回准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构造伪数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 构造数据集\n",
    "X,Y = make_classification(n_samples=1000,\n",
    "                          n_features=5,\n",
    "                          n_informative=3,\n",
    "                          n_redundant=1,\n",
    "                          n_repeated=1,\n",
    "                          n_classes=2,\n",
    "                         )\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 待优化的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'gamma':[0.001,0.01,0.1,1],\n",
    "    'C':[0.002,0.03,0.4,1.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 网格搜索+交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score:0.92\n",
      "Best parameters:{'C': 1.2, 'gamma': 1}\n",
      "Best score on train set:0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiyang/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 实例化一个GridSearchCV类\n",
    "grid_search = GridSearchCV(estimator=SVC(),param_grid=param_grid,cv=10)\n",
    "# 将训练集进一步划分为训练集和验证集，训练模型,寻找最优参数组合\n",
    "# 同时使用最优参数组合实例化的那个SVC estimator\n",
    "grid_search.fit(X_train,Y_train)\n",
    "# 用最优参数组合来评估测试集的性能指标得分\n",
    "print(\"Test set score:{:.2f}\".format(grid_search.score(X_test,Y_test)))\n",
    "print(\"Best parameters:{}\".format(grid_search.best_params_))\n",
    "print(\"Best score on train set:{:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSearch:随机搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**核心思想**:从参数组合中随机抽取组合来优化模型。对于每个参数,可以指定在可能值上的分布或离散选择的列表，候选的每个参数值都是均匀取样获得的。对于连续参数，指定连续分布以充分利用随机化，这样有助于**n_iter(需要随机抽取的组合个数)**总是趋向于更精细的搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用随机搜索的前提"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 数据规模大，精确的结果难以在一定时间计算出\n",
    "2. 结果的些许的不精确能够被接受\n",
    "3. 求取的结果是最优化（optimization）问题，有一个成本计算模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机搜索+交叉验证: RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV 参数和类方法介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomizedSearchCV() 将**随机搜索**和**交叉验证**结合起来，实现了fit()，predict(),score()等方法，重要的参数如下:\n",
    "1. estimator:实现了scikit-learn的estimator接口，scikit-learn提供的模型都可以\n",
    "2. param_distributions:待优化的参数字典，如果是参数是离散取值，则值是列表形式；如果参数是连续分布的，则用scipy.stats模块表示分布，如{'gamma': scipy.stats.uniform(scale=.1)}表示参数gamma服从均匀分布\n",
    "3. n_iter:表示随机抽取的参数组合个数\n",
    "4. cv:默认为None，代表3折交叉验证，可以取int，代表K折交叉验证\n",
    "\n",
    "random_search = RandomizedSearchCV()\n",
    "RandomizedSearchCV()类实现的方法:\n",
    "1. random_search.fit(X,Y):用来训练模型和寻找最优参数组合，random_search是那个最优参数组合的模型\n",
    "2. random_search.predict(X):在random_search.fit(X,Y)之后使用，用最优参数组合的那个模型来预测，返回类别\n",
    "3. random_search.predict_log_proba(X):在random_search.fit(X,Y)之后使用，用最优参数组合的那个模型来预测，返回取对数后的概率值\n",
    "4. random_search.predict_proba(X):在random_search.fit(X,Y)之后使用，用最优参数组合的那个模型来预测，返回概率值\n",
    "5. random_search.score(X,Y):在random_search.fit(X,Y)之后使用，用最优参数组合的那个模型来评估测试集，返回准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造伪数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 构造数据集\n",
    "X,Y = make_classification(n_samples=1000,\n",
    "                          n_features=5,\n",
    "                          n_informative=3,\n",
    "                          n_redundant=1,\n",
    "                          n_repeated=1,\n",
    "                          n_classes=2,\n",
    "                         )\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 待优化的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'gamma':[0.001,0.01,0.1,1],\n",
    "    'C':[0.002,0.03,0.4,1.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机搜索+交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score:0.86\n",
      "Best parameters:{'gamma': 1, 'C': 0.4}\n",
      "Best score on train set:0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 实例化一个RandomizedSearchCV类\n",
    "random_search = RandomizedSearchCV(estimator=SVC(),\n",
    "                                   param_distributions=param_distributions,\n",
    "                                   n_iter = 10,\n",
    "                                   cv=10)\n",
    "# 将训练集进一步划分为训练集和验证集，训练模型,寻找最优参数组合\n",
    "# 同时使用最优参数组合实例化的那个SVC estimator\n",
    "random_search.fit(X_train,Y_train)\n",
    "# 用最优参数组合来评估测试集的性能指标得分\n",
    "print(\"Test set score:{:.2f}\".format(random_search.score(X_test,Y_test)))\n",
    "print(\"Best parameters:{}\".format(random_search.best_params_))\n",
    "print(\"Best score on train set:{:.2f}\".format(random_search.best_score_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
